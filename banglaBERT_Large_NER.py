# -*- coding: utf-8 -*-
"""conll-huggingface-named-entity-recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Kw7AOWP4PJUURcu6oQrgQZ-GFytzbyGX

<div width="100%">
    <img width="100%" src="https://storage.googleapis.com/kaggle-datasets-images/1232095/2056195/3da2fe161c2e35efefa75f990b545d32/dataset-cover.png" />
</div>
"""

try:
  from google.colab import drive
  drive.mount('/content/drive')
  colab = True
except:
  colab = False

import numpy as np
import pandas as pd
# if colab:  !pip install transformers
from transformers import AutoTokenizer

from tqdm import tqdm
import tensorflow as tf

import matplotlib.pyplot as plt

"""<h1 id="dataset" style="color:#black; background:#a6e22d; border:0.5px dotted #black;"> 
    <center>Dataset
        <a class="anchor-link" href="#dataset" target="_self">¶</a>
    </center>
</h1>
"""

def convert_to_csv(file):
  
  with open(file) as f:
      # read csv file as pandas dataframe
      df = pd.read_csv(f, sep=',', 
        # names=['Sentence_id', 'Word', 'Tag']
        )
      # group by sentence_id and create list of words and list of tags
      df = df.groupby('sentence_id').agg({'word': lambda x: list(x), 'tag': lambda x: list(x)})
      # create pair of 2nd and 3rd column (word , tag)
      df['word_tag'] = df.apply(lambda x: list(zip(x['word'], x['tag'])), axis=1)
      # create list of pair of 2nd and 3rd column (word , tag)
      word_tag_list = df['word_tag'].tolist()
      
      return word_tag_list

if colab : train_file = '/content/drive/MyDrive/NLP_Hackathon_2023/train_generic.csv'
else : train_file = 'data/train_generic_no_punc.csv'
samples = convert_to_csv(train_file)

print(samples[:5])

schema = ['_'] + sorted({tag for sentence in samples 
                             for _, tag in sentence})

"""<h1 id="model" style="color:#black; background:#ef60b4; border:0.5px dotted #black;"> 
    <center>Model
        <a class="anchor-link" href="#model" target="_self">¶</a>
    </center>
</h1>
"""

from transformers import AutoConfig, TFAutoModelForTokenClassification

# MODEL_NAME = 'bert-base-cased' 
# MODEL_NAME = "sagorsarker/bangla-bert-base"

# MODEL_NAME = "csebuetnlp/banglabert"
MODEL_NAME = "csebuetnlp/banglabert_large"

# old_model = 'sagorbert_0_100/sagorsarker-bangla-bert-base.h5'
# old_model = '/mnt/y/_data/nlp23/bertlarge_25_45/csebuetnlp-banglabert_large.h5'
# old_model = "/mnt/y/_data/nlp23/strat/bertlarge20-40/csebuetnlp-banglabert_large.h5"
old_model = "/mnt/y/_data/nlp23/bertlarge_fulldataset_40_45/csebuetnlp-banglabert_large.h5"

if colab: dev_file = '/content/drive/MyDrive/NLP_Hackathon_2023/dev_generic.csv'
else : dev_file = 'data/dev_generic_no_punc.csv'

# EPOCHS=100
EPOCHS=40
BATCH_SIZE=64

continue_train = False
# continue_train = True

config = AutoConfig.from_pretrained(MODEL_NAME, num_labels=len(schema)) 
if continue_train:
  model = TFAutoModelForTokenClassification.from_pretrained(old_model, from_pt=False,
                                                           config=config)
else:
  model = TFAutoModelForTokenClassification.from_pretrained(MODEL_NAME , from_pt=True,
                                                          config=config)
model.summary()

"""<h1 id="tokenize" style="color:#black; background:#fc9720; border:0.5px dotted #black;"> 
    <center>Tokenize
        <a class="anchor-link" href="#tokenize" target="_self">¶</a>
    </center>
</h1>
"""

tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)

def tokenize_sample(sample):
    seq = [
               (subtoken, tag)
               for token, tag in sample
               for subtoken in tokenizer(token)['input_ids'][1:-1]
           ]
    return [(3, 'O')] + seq + [(4, 'O')]

def preprocess(samples):
    tag_index = {tag: i for i, tag in enumerate(schema)}
    tokenized_samples = list(tqdm(map(tokenize_sample, samples)))
    max_len = max(map(len, tokenized_samples))
    X = np.zeros((len(samples), max_len), dtype=np.int32)
    y = np.zeros((len(samples), max_len), dtype=np.int32)
    for i, sentence in enumerate(tokenized_samples):
        for j, (subtoken_id, tag) in enumerate(sentence):
            X[i, j] = subtoken_id
            y[i,j] = tag_index[tag]
    return X, y

# dev set load

# split into train and test
from sklearn.model_selection import train_test_split
strat = []
blacklist = ["B-CW", "I-CW", "B-PROD", "I-CORP", "I-PROD", "I-LOC"]
for sample in samples:
  strat.append(0)
  for word in sample: 
    if word[1] in blacklist: 
        strat[-1] = 1
        break
        
# test size = 0.2
train_samples, test_samples = train_test_split(samples, test_size=0.0001, random_state=42, 
                                            # stratify=strat
                            )

X_train, y_train = preprocess(train_samples)
X_test, y_test = preprocess(test_samples)


dev_samples = convert_to_csv(dev_file)
X_valid, y_valid = preprocess(dev_samples)

y_valid.shape

y_train.shape

y_test.shape

from keras import backend as K

# def f1(y_true, y_pred):
#     def recall(y_true, y_pred):
#         true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
#         possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
#         recall = true_positives / (possible_positives + K.epsilon())
#         return recall

#     def precision(y_true, y_pred):
#         true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
#         predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
#         precision = true_positives / (predicted_positives + K.epsilon())
#         return precision

#     precision = precision(y_true, y_pred)
#     recall = recall(y_true, y_pred)
#     return 2*((precision*recall)/(precision+recall+K.epsilon()))

### Define F1 measures: F1 = 2 * (precision * recall) / (precision + recall)

def custom_f1(y_true, y_pred):
    def recall_m(y_true, y_pred):
        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
        Positives = K.sum(K.round(K.clip(y_true, 0, 1)))

        recall = TP / (Positives+K.epsilon())
        return recall


    def precision_m(y_true, y_pred):
        TP = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
        Pred_Positives = K.sum(K.round(K.clip(y_pred, 0, 1)))

        precision = TP / (Pred_Positives+K.epsilon())
        return precision

    precision, recall = precision_m(y_true, y_pred), recall_m(y_true, y_pred)

    return 2*((precision*recall)/(precision+recall+K.epsilon()))

"""<h1 id="training" style="color:#black; background:#bababa; border:0.5px dotted #black;"> 
    <center>Training
        <a class="anchor-link" href="#training" target="_self">¶</a>
    </center>
</h1>
"""


optimizer = tf.keras.optimizers.Adam(lr=0.000001)
loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
model.compile(optimizer=optimizer, loss=loss, 
              metrics=["accuracy" , 
              # tf.keras.metrics.Precision(name="precision")
              ]
              #metrics = "accuracy"
)
history = model.fit(tf.constant(X_train), tf.constant(y_train),
                    validation_data=(X_test, y_test), 
                    epochs=EPOCHS, 
                    batch_size=BATCH_SIZE)

#!pip list | grep tensorflow



"""<h1 id="results" style="color:#black; background:#2fbbab; border:0.5px dotted #black;"> 
    <center>Results
        <a class="anchor-link" href="#results" target="_self">¶</a>
    </center>
</h1>

## Training results
"""

plt.figure(figsize=(14,8))
plt.title('Losses')
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Valid Loss')
plt.ylabel('Loss')
plt.xlabel('Epochs')
plt.legend()
# plt.show()
plt.savefig('loss.png')

plt.figure(figsize=(14,8))
plt.title('Accuracies')
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Valid Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.legend()
# plt.show()
plt.savefig('accuracy.png')

"""## Validation results"""

[loss, accuracy] = model.evaluate(X_valid, y_valid)
print("Loss:%1.3f, Accuracy:%1.3f" % (loss, accuracy))

# Find the f1 score of the model output
from sklearn.metrics import f1_score
y_pred = model.predict(X_valid).logits
y_pred = np.argmax(y_pred, axis=-1)
y_pred = y_pred.reshape(-1)
y_pred = y_pred.flatten().squeeze()
y_valid = y_valid.flatten().squeeze()
f1 = f1_score(y_valid, y_pred, average='macro')
print(f1)

from sklearn.metrics import classification_report
tag_index = {tag: i for i, tag in enumerate(schema)}
labels = []
for key in tag_index.keys():
    labels.append(key)
    
print(classification_report(y_valid , y_pred , digits = 4 , target_names=labels))

if colab : model.save_weights('/content/drive/MyDrive/NLP_Hackathon_2023/'+MODEL_NAME+'.h5')
else : model.save_weights('../'+"-".join(MODEL_NAME.split("/"))+'.h5')

